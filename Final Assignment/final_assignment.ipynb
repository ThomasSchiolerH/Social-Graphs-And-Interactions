{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from newspaper import Article\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NewsAPI Client\n",
    "api_key = \"\"  # Replace with API key\n",
    "newsapi = NewsApiClient(api_key=api_key)\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = \"news_articles_election_candidates_expanded.csv\"\n",
    "full_content_file = \"news_articles_election_candidates_full_content.csv\"\n",
    "\n",
    "# Function to fetch full article content using newspaper3k\n",
    "def fetch_full_content(article_url):\n",
    "    try:\n",
    "        article = Article(article_url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return article.text  # Return the full article text\n",
    "    except Exception as e:\n",
    "        return None  # Return None if there is an error\n",
    "\n",
    "# Set new date range\n",
    "start_date = datetime.date(2024, 10, 12)  # Continue from where the previous script left off\n",
    "end_date = datetime.date(2024, 8, 1)  # Adjust end date as needed for backward collection\n",
    "\n",
    "# Prepare to store results\n",
    "articles_data = []\n",
    "\n",
    "# Expanded search queries\n",
    "queries = [\n",
    "    \"2024 Presidential election\",\n",
    "    \"US election AND (Donald Trump OR Kamala Harris)\",\n",
    "    \"Biden administration AND 2024 election\",\n",
    "    \"(Donald Trump OR Trump) AND 2024 election\",\n",
    "    \"(Kamala Harris OR Harris) AND 2024 election\",\n",
    "    \"Campaign financing AND 2024 election\",\n",
    "    \"Voter turnout AND 2024 election\",\n",
    "    \"Presidential debate AND 2024 election\",\n",
    "    \"(Donald Trump OR Trump) AND rally AND 2024\",\n",
    "    \"(Kamala Harris OR Harris) AND speech AND 2024\",\n",
    "    \"(Donald Trump OR Kamala Harris) AND 2024 election\",\n",
    "    \"(Trump OR Harris) AND campaign AND 2024 election\"\n",
    "]\n",
    "\n",
    "# Track API request count to avoid exceeding limits\n",
    "request_count = 0\n",
    "max_requests = 100  # Free-tier daily API limit\n",
    "\n",
    "# Load existing expanded and full content CSV files\n",
    "existing_expanded_data = pd.read_csv(input_file) if os.path.exists(input_file) else pd.DataFrame()\n",
    "existing_full_content_data = pd.read_csv(full_content_file) if os.path.exists(full_content_file) else pd.DataFrame()\n",
    "\n",
    "# Track URLs to avoid duplicates\n",
    "existing_urls = set(existing_expanded_data[\"url\"]) if not existing_expanded_data.empty else set()\n",
    "processed_urls = set(existing_full_content_data[\"url\"]) if not existing_full_content_data.empty else set()\n",
    "\n",
    "# Fetch new articles from NewsAPI\n",
    "current_date = start_date\n",
    "while current_date >= end_date:\n",
    "    # Convert date to string for API\n",
    "    date_str = current_date.strftime('%Y-%m-%d')\n",
    "    print(f\"Fetching articles for {date_str}...\")\n",
    "\n",
    "    for query in queries:\n",
    "        try:\n",
    "            # Check if API limit is reached\n",
    "            if request_count >= max_requests:\n",
    "                print(\"Reached API limit for the day. Exiting script.\")\n",
    "                sys.exit()\n",
    "\n",
    "            # Fetch articles for the current query and date\n",
    "            response = newsapi.get_everything(\n",
    "                q=query,\n",
    "                from_param=date_str,\n",
    "                to=date_str,\n",
    "                language=\"en\",\n",
    "                sort_by=\"relevancy\",  # Fetch relevant articles\n",
    "                page_size=100  # Max articles per API call\n",
    "            )\n",
    "\n",
    "            # Increment request count\n",
    "            request_count += 1\n",
    "\n",
    "            if response.get('status') != 'ok':\n",
    "                print(f\"API error: {response.get('message')}\")\n",
    "                sys.exit()\n",
    "\n",
    "            # Process the articles\n",
    "            if response.get('articles'):\n",
    "                for article in response['articles']:\n",
    "                    # Only add new articles that are not already saved\n",
    "                    if article['url'] not in existing_urls:\n",
    "                        articles_data.append({\n",
    "                            \"query\": query,  # Include the query used for tracking\n",
    "                            \"source\": article['source']['name'],\n",
    "                            \"author\": article['author'],\n",
    "                            \"title\": article['title'],\n",
    "                            \"description\": article['description'],\n",
    "                            \"url\": article['url'],\n",
    "                            \"published_at\": article['publishedAt'],\n",
    "                            \"content\": article['content']\n",
    "                        })\n",
    "                        # Add the URL to the set of existing URLs\n",
    "                        existing_urls.add(article['url'])\n",
    "        except Exception as e:\n",
    "            # Log the error to a file\n",
    "            with open(\"error_log.txt\", \"a\") as log_file:\n",
    "                log_file.write(f\"Error fetching articles for {query} on {date_str}: {e}\\n\")\n",
    "            print(f\"Error fetching articles for {query} on {date_str}: {e}\")\n",
    "    \n",
    "    # Move to the previous day\n",
    "    current_date -= datetime.timedelta(days=1)\n",
    "\n",
    "    # Avoid hitting API limits by adding a small delay between requests\n",
    "    time.sleep(1)\n",
    "\n",
    "# Save new articles to the expanded CSV file\n",
    "if articles_data:\n",
    "    new_data_df = pd.DataFrame(articles_data)\n",
    "    new_data_df.to_csv(input_file, mode='a', header=not os.path.exists(input_file), index=False)\n",
    "    print(f\"Appended {len(new_data_df)} new articles to '{input_file}'.\")\n",
    "\n",
    "# Extract full content for new articles only\n",
    "new_urls = {article[\"url\"] for article in articles_data}  # URLs of newly fetched articles\n",
    "urls_to_process = new_urls - processed_urls  # Exclude already processed URLs\n",
    "\n",
    "if urls_to_process:\n",
    "    full_content_data = []\n",
    "    for url in urls_to_process:\n",
    "        print(f\"Fetching full content for {url}...\")\n",
    "        full_content = fetch_full_content(url)\n",
    "        if full_content:\n",
    "            full_content_data.append({\n",
    "                \"url\": url,\n",
    "                \"full_content\": full_content\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Failed to fetch full content for {url}\")\n",
    "\n",
    "    # Append full content to the full content CSV file\n",
    "    if full_content_data:\n",
    "        full_content_df = pd.DataFrame(full_content_data)\n",
    "        full_content_df.to_csv(full_content_file, mode='a', header=not os.path.exists(full_content_file), index=False)\n",
    "        print(f\"Appended {len(full_content_df)} new full content articles to '{full_content_file}'.\")\n",
    "else:\n",
    "    print(\"No new articles to process for full content.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9610 entries, 0 to 9609\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   query         9610 non-null   object\n",
      " 1   source        9610 non-null   object\n",
      " 2   author        9093 non-null   object\n",
      " 3   title         9607 non-null   object\n",
      " 4   description   9598 non-null   object\n",
      " 5   url           9610 non-null   object\n",
      " 6   published_at  9610 non-null   object\n",
      " 7   content       9610 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 600.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = 'news_articles_election_candidates_expanded.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data.head()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9610 entries, 0 to 9609\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   query         9610 non-null   object\n",
      " 1   source        9610 non-null   object\n",
      " 2   author        9093 non-null   object\n",
      " 3   title         9607 non-null   object\n",
      " 4   description   9598 non-null   object\n",
      " 5   url           9610 non-null   object\n",
      " 6   published_at  9610 non-null   object\n",
      " 7   content       9610 non-null   object\n",
      " 8   full_content  7556 non-null   object\n",
      "dtypes: object(9)\n",
      "memory usage: 675.8+ KB\n"
     ]
    }
   ],
   "source": [
    "file_path = 'news_articles_election_candidates_full_content.csv'\n",
    "data_full_content = pd.read_csv(file_path)\n",
    "\n",
    "data_full_content.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove entries with missing full content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_content = pd.read_csv('news_articles_election_candidates_full_content_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>published_at</th>\n",
       "      <th>content</th>\n",
       "      <th>full_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024 Presidential election</td>\n",
       "      <td>Wired</td>\n",
       "      <td>Lily Hay Newman, Tess Owen</td>\n",
       "      <td>Russia Is Going All Out on Election Day Interf...</td>\n",
       "      <td>Along with other foreign influence operations—...</td>\n",
       "      <td>https://www.wired.com/story/russia-election-di...</td>\n",
       "      <td>2024-11-05T21:04:35Z</td>\n",
       "      <td>As the 2024 US presidential election comes to ...</td>\n",
       "      <td>As the 2024 US presidential election comes to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024 Presidential election</td>\n",
       "      <td>The Verge</td>\n",
       "      <td>Justine Calma</td>\n",
       "      <td>Apple News will let you watch election results...</td>\n",
       "      <td>On Election Day in the US, Apple News is rolli...</td>\n",
       "      <td>https://www.theverge.com/2024/11/5/24288777/el...</td>\n",
       "      <td>2024-11-05T16:34:12Z</td>\n",
       "      <td>Image: Cath Virginia / The Verge\\r\\n\\n \\n\\n Fo...</td>\n",
       "      <td>For anyone obsessively watching election resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024 Presidential election</td>\n",
       "      <td>NPR</td>\n",
       "      <td>Megan Pratz</td>\n",
       "      <td>Here's how NPR will report the 2024 election r...</td>\n",
       "      <td>NPR relies on results and race calls from The ...</td>\n",
       "      <td>https://www.npr.org/2024/11/04/g-s1-31268/2024...</td>\n",
       "      <td>2024-11-05T10:00:00Z</td>\n",
       "      <td>Voters have been voting, ballots will be count...</td>\n",
       "      <td>Here's how NPR will report the 2024 election r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024 Presidential election</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>insider@insider.com (John L. Dorman,Kelsey Vla...</td>\n",
       "      <td>The 2024 presidential election may come down t...</td>\n",
       "      <td>Election results in the swing states of Arizon...</td>\n",
       "      <td>https://www.businessinsider.com/what-are-2024-...</td>\n",
       "      <td>2024-11-05T22:13:18Z</td>\n",
       "      <td>Over the past two decades, the road to the Whi...</td>\n",
       "      <td>On Election Day 2024, both parties are eyeing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024 Presidential election</td>\n",
       "      <td>CNET</td>\n",
       "      <td>Thomas Kika</td>\n",
       "      <td>How Do I Keep Track of Official Election Resul...</td>\n",
       "      <td>An avalanche of Election Day 2024 coverage is ...</td>\n",
       "      <td>https://www.cnet.com/tech/services-and-softwar...</td>\n",
       "      <td>2024-11-05T17:45:00Z</td>\n",
       "      <td>As if the 2024 election reporting could be any...</td>\n",
       "      <td>All anyone is talking about today is the presi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        query            source  \\\n",
       "0  2024 Presidential election             Wired   \n",
       "1  2024 Presidential election         The Verge   \n",
       "2  2024 Presidential election               NPR   \n",
       "3  2024 Presidential election  Business Insider   \n",
       "4  2024 Presidential election              CNET   \n",
       "\n",
       "                                              author  \\\n",
       "0                         Lily Hay Newman, Tess Owen   \n",
       "1                                      Justine Calma   \n",
       "2                                        Megan Pratz   \n",
       "3  insider@insider.com (John L. Dorman,Kelsey Vla...   \n",
       "4                                        Thomas Kika   \n",
       "\n",
       "                                               title  \\\n",
       "0  Russia Is Going All Out on Election Day Interf...   \n",
       "1  Apple News will let you watch election results...   \n",
       "2  Here's how NPR will report the 2024 election r...   \n",
       "3  The 2024 presidential election may come down t...   \n",
       "4  How Do I Keep Track of Official Election Resul...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Along with other foreign influence operations—...   \n",
       "1  On Election Day in the US, Apple News is rolli...   \n",
       "2  NPR relies on results and race calls from The ...   \n",
       "3  Election results in the swing states of Arizon...   \n",
       "4  An avalanche of Election Day 2024 coverage is ...   \n",
       "\n",
       "                                                 url          published_at  \\\n",
       "0  https://www.wired.com/story/russia-election-di...  2024-11-05T21:04:35Z   \n",
       "1  https://www.theverge.com/2024/11/5/24288777/el...  2024-11-05T16:34:12Z   \n",
       "2  https://www.npr.org/2024/11/04/g-s1-31268/2024...  2024-11-05T10:00:00Z   \n",
       "3  https://www.businessinsider.com/what-are-2024-...  2024-11-05T22:13:18Z   \n",
       "4  https://www.cnet.com/tech/services-and-softwar...  2024-11-05T17:45:00Z   \n",
       "\n",
       "                                             content  \\\n",
       "0  As the 2024 US presidential election comes to ...   \n",
       "1  Image: Cath Virginia / The Verge\\r\\n\\n \\n\\n Fo...   \n",
       "2  Voters have been voting, ballots will be count...   \n",
       "3  Over the past two decades, the road to the Whi...   \n",
       "4  As if the 2024 election reporting could be any...   \n",
       "\n",
       "                                        full_content  \n",
       "0  As the 2024 US presidential election comes to ...  \n",
       "1  For anyone obsessively watching election resul...  \n",
       "2  Here's how NPR will report the 2024 election r...  \n",
       "3  On Election Day 2024, both parties are eyeing ...  \n",
       "4  All anyone is talking about today is the presi...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows (articles): 7556\n",
      "Number of variables (columns): 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows (articles):\", data_full_content.shape[0])\n",
    "print(\"Number of variables (columns):\", data_full_content.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique media outlets: 454\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of unique media outlets\n",
    "unique_media_outlets = data_full_content['source'].nunique()\n",
    "\n",
    "# Display the number of unique media outlets\n",
    "print(f\"Number of unique media outlets: {unique_media_outlets}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 842\n",
      "Number of edges: 34386\n",
      "Sample nodes: [('Donald Trump', {'articles': [0, 1, 3, 4, 5, 6, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 24, 25, 27, 29, 30, 33, 34, 38, 40, 42, 43, 45, 49, 50, 51, 52, 53, 55, 57, 58, 64, 65, 67, 70, 71, 74, 75, 76, 77, 78, 82, 83, 84, 86, 91, 92, 93, 94, 95, 96, 97, 98, 99]}), ('Hillary Clinton', {'articles': [0, 33, 34, 3, 7, 12, 17, 49, 19, 82, 21, 92, 95]}), ('Clinton', {'articles': [0, 58, 3]}), ('Brad Raffensperger', {'articles': [0]}), ('Cait Conley', {'articles': [0]})]\n",
      "Sample edges: [('Donald Trump', 'Brad Raffensperger', {'weight': 1}), ('Donald Trump', 'Tim Walz', {'weight': 7}), ('Donald Trump', 'Hillary Clinton', {'weight': 13}), ('Donald Trump', 'Adrian Fontes', {'weight': 2}), ('Donald Trump', 'Cait Conley', {'weight': 1})]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import spacy\n",
    "from collections import defaultdict\n",
    "\n",
    "# Process only the first 100 articles\n",
    "data_sample = data_full_content.head(100)\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize mappings for mentions\n",
    "article_mentions = defaultdict(set)  # Maps article index to mentioned politicians\n",
    "politician_mentions = defaultdict(set)  # Maps politician to articles they're mentioned in\n",
    "\n",
    "# Perform NER to extract names of politicians dynamically\n",
    "for idx, row in data_sample.iterrows():\n",
    "    content = row['full_content']\n",
    "    doc = nlp(content)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":  # Identify named entities classified as \"PERSON\"\n",
    "            politician_name = ent.text\n",
    "            article_mentions[idx].add(politician_name)\n",
    "            politician_mentions[politician_name].add(idx)\n",
    "\n",
    "# Create the network graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with attributes (politicians and articles)\n",
    "for politician, articles in politician_mentions.items():\n",
    "    G.add_node(politician, articles=list(articles))\n",
    "\n",
    "# Add edges based on co-mentions in articles\n",
    "for article_idx, mentioned_politicians in article_mentions.items():\n",
    "    mentioned_politicians = list(mentioned_politicians)\n",
    "    for i in range(len(mentioned_politicians)):\n",
    "        for j in range(i + 1, len(mentioned_politicians)):\n",
    "            p1, p2 = mentioned_politicians[i], mentioned_politicians[j]\n",
    "            if G.has_edge(p1, p2):\n",
    "                G[p1][p2]['weight'] += 1\n",
    "            else:\n",
    "                G.add_edge(p1, p2, weight=1)\n",
    "\n",
    "# Output graph information\n",
    "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "print(f\"Sample nodes: {list(G.nodes(data=True))[:5]}\")\n",
    "print(f\"Sample edges: {list(G.edges(data=True))[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine e.g. hilary and hilary clinton\n",
    "Make sure author is not a node e.g."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02805SG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
