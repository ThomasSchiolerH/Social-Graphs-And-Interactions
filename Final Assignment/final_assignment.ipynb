{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment 1 (October 5â€“October 19)\n",
    "\n",
    "## API Keys 1 & 2: General election news.\n",
    "\n",
    "\"2024 Presidential election\"\n",
    "\"US election AND Trump AND Harris\"\n",
    "\"Biden administration AND 2024 election\"\n",
    "\n",
    "\n",
    "## API Key 3: Candidate-specific news.\n",
    "\n",
    "\"Donald Trump AND 2024 election\"\n",
    "\"Kamala Harris AND 2024 election\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Script Key 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "API_KEY = \"your_newsapi_key_1\"  # Replace with API key 1\n",
    "BASE_URL = \"https://newsapi.org/v2/everything\"\n",
    "\n",
    "def fetch_articles(query, from_date, to_date, max_requests=100):\n",
    "    articles = []\n",
    "    for page in range(1, max_requests + 1):\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"from\": from_date,\n",
    "            \"to\": to_date,\n",
    "            \"language\": \"en\",\n",
    "            \"pageSize\": 100,\n",
    "            \"page\": page,\n",
    "            \"apiKey\": API_KEY\n",
    "        }\n",
    "        response = requests.get(BASE_URL, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            articles.extend(data[\"articles\"])\n",
    "            if len(data[\"articles\"]) < 100:\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            break\n",
    "        time.sleep(1)\n",
    "    return articles\n",
    "\n",
    "# Define date range for Segment 1\n",
    "start_date = datetime(2024, 10, 5)\n",
    "end_date = datetime(2024, 10, 19)\n",
    "\n",
    "from_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "to_date = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f\"Fetching articles from {from_date} to {to_date}\")\n",
    "\n",
    "queries = [\"2024 Presidential election\", \"US election AND Trump AND Harris\", \"Biden administration AND 2024 election\"]\n",
    "all_articles = []\n",
    "\n",
    "# Fetch articles for each query\n",
    "for query in queries:\n",
    "    all_articles.extend(fetch_articles(query, from_date, to_date))\n",
    "\n",
    "df = pd.DataFrame(all_articles)\n",
    "file_name = f\"general_{from_date}_to_{to_date}.csv\"\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"Saved {len(all_articles)} articles for General Election News.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Script key 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "API_KEY = \"your_newsapi_key_2\"  # Replace with API key 2\n",
    "BASE_URL = \"https://newsapi.org/v2/everything\"\n",
    "\n",
    "def fetch_articles(query, from_date, to_date, max_requests=100):\n",
    "    articles = []\n",
    "    for page in range(1, max_requests + 1):\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"from\": from_date,\n",
    "            \"to\": to_date,\n",
    "            \"language\": \"en\",\n",
    "            \"pageSize\": 100,\n",
    "            \"page\": page,\n",
    "            \"apiKey\": API_KEY\n",
    "        }\n",
    "        response = requests.get(BASE_URL, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            articles.extend(data[\"articles\"])\n",
    "            if len(data[\"articles\"]) < 100:\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            break\n",
    "        time.sleep(1)\n",
    "    return articles\n",
    "\n",
    "# Define date range for Segment 1\n",
    "start_date = datetime(2024, 10, 5)\n",
    "end_date = datetime(2024, 10, 19)\n",
    "\n",
    "from_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "to_date = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f\"Fetching articles from {from_date} to {to_date}\")\n",
    "\n",
    "queries = [\"2024 Presidential election\", \"US election AND Trump AND Harris\", \"Biden administration AND 2024 election\"]\n",
    "all_articles = []\n",
    "\n",
    "# Fetch articles for each query\n",
    "for query in queries:\n",
    "    all_articles.extend(fetch_articles(query, from_date, to_date))\n",
    "\n",
    "df = pd.DataFrame(all_articles)\n",
    "file_name = f\"general_{from_date}_to_{to_date}.csv\"\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"Saved {len(all_articles)} articles for General Election News.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Script key 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "API_KEY = \"your_newsapi_key_3\"  # Replace with API key 3\n",
    "BASE_URL = \"https://newsapi.org/v2/everything\"\n",
    "\n",
    "def fetch_articles(query, from_date, to_date, max_requests=100):\n",
    "    articles = []\n",
    "    for page in range(1, max_requests + 1):\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"from\": from_date,\n",
    "            \"to\": to_date,\n",
    "            \"language\": \"en\",\n",
    "            \"pageSize\": 100,\n",
    "            \"page\": page,\n",
    "            \"apiKey\": API_KEY\n",
    "        }\n",
    "        response = requests.get(BASE_URL, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            articles.extend(data[\"articles\"])\n",
    "            if len(data[\"articles\"]) < 100:\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            break\n",
    "        time.sleep(1)\n",
    "    return articles\n",
    "\n",
    "# Define date range for Segment 1\n",
    "start_date = datetime(2024, 10, 5)\n",
    "end_date = datetime(2024, 10, 19)\n",
    "\n",
    "from_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "to_date = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f\"Fetching articles from {from_date} to {to_date}\")\n",
    "\n",
    "queries = [\"Donald Trump AND 2024 election\", \"Kamala Harris AND 2024 election\"]\n",
    "all_articles = []\n",
    "\n",
    "# Fetch articles for each query\n",
    "for query in queries:\n",
    "    all_articles.extend(fetch_articles(query, from_date, to_date))\n",
    "\n",
    "df = pd.DataFrame(all_articles)\n",
    "file_name = f\"general_{from_date}_to_{to_date}.csv\"\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"Saved {len(all_articles)} articles for General Election News.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# script 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "API_KEY = \"your_newsapi_key_4\"  # Replace with API key 4\n",
    "BASE_URL = \"https://newsapi.org/v2/everything\"\n",
    "\n",
    "def fetch_articles(query, from_date, to_date, max_requests=100):\n",
    "    articles = []\n",
    "    for page in range(1, max_requests + 1):\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"from\": from_date,\n",
    "            \"to\": to_date,\n",
    "            \"language\": \"en\",\n",
    "            \"pageSize\": 100,\n",
    "            \"page\": page,\n",
    "            \"apiKey\": API_KEY\n",
    "        }\n",
    "        response = requests.get(BASE_URL, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            articles.extend(data[\"articles\"])\n",
    "            if len(data[\"articles\"]) < 100:\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            break\n",
    "        time.sleep(1)\n",
    "    return articles\n",
    "\n",
    "# Define date range for Segment 1\n",
    "start_date = datetime(2024, 10, 5)\n",
    "end_date = datetime(2024, 10, 19)\n",
    "\n",
    "from_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "to_date = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f\"Fetching articles from {from_date} to {to_date}\")\n",
    "\n",
    "queries = [\"Presidential debate AND 2024\", \"Trump rally AND 2024\", \"Harris speech AND 2024\"]\n",
    "all_articles = []\n",
    "\n",
    "# Fetch articles for each query\n",
    "for query in queries:\n",
    "    all_articles.extend(fetch_articles(query, from_date, to_date))\n",
    "\n",
    "df = pd.DataFrame(all_articles)\n",
    "file_name = f\"general_{from_date}_to_{to_date}.csv\"\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"Saved {len(all_articles)} articles for General Election News.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Script 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "API_KEY = \"your_newsapi_key_5\"  # Replace with API key 5\n",
    "BASE_URL = \"https://newsapi.org/v2/everything\"\n",
    "\n",
    "def fetch_articles(query, from_date, to_date, max_requests=100):\n",
    "    articles = []\n",
    "    for page in range(1, max_requests + 1):\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"from\": from_date,\n",
    "            \"to\": to_date,\n",
    "            \"language\": \"en\",\n",
    "            \"pageSize\": 100,\n",
    "            \"page\": page,\n",
    "            \"apiKey\": API_KEY\n",
    "        }\n",
    "        response = requests.get(BASE_URL, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            articles.extend(data[\"articles\"])\n",
    "            if len(data[\"articles\"]) < 100:\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            break\n",
    "        time.sleep(1)\n",
    "    return articles\n",
    "\n",
    "# Define date range for Segment 1\n",
    "start_date = datetime(2024, 10, 5)\n",
    "end_date = datetime(2024, 10, 19)\n",
    "\n",
    "from_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "to_date = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f\"Fetching articles from {from_date} to {to_date}\")\n",
    "\n",
    "queries = [\"Presidential debate AND 2024\", \"Trump rally AND 2024\", \"Harris speech AND 2024\"]\n",
    "all_articles = []\n",
    "\n",
    "# Fetch articles for each query\n",
    "for query in queries:\n",
    "    all_articles.extend(fetch_articles(query, from_date, to_date))\n",
    "\n",
    "df = pd.DataFrame(all_articles)\n",
    "file_name = f\"general_{from_date}_to_{to_date}.csv\"\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"Saved {len(all_articles)} articles for General Election News.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Script 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "API_KEY = \"your_newsapi_key_6\"  # Replace with API key 6\n",
    "BASE_URL = \"https://newsapi.org/v2/everything\"\n",
    "\n",
    "def fetch_articles(query, from_date, to_date, max_requests=100):\n",
    "    articles = []\n",
    "    for page in range(1, max_requests + 1):\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"from\": from_date,\n",
    "            \"to\": to_date,\n",
    "            \"language\": \"en\",\n",
    "            \"pageSize\": 100,\n",
    "            \"page\": page,\n",
    "            \"apiKey\": API_KEY\n",
    "        }\n",
    "        response = requests.get(BASE_URL, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            articles.extend(data[\"articles\"])\n",
    "            if len(data[\"articles\"]) < 100:\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            break\n",
    "        time.sleep(1)\n",
    "    return articles\n",
    "\n",
    "# Define date range for Segment 1\n",
    "start_date = datetime(2024, 10, 5)\n",
    "end_date = datetime(2024, 10, 19)\n",
    "\n",
    "from_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "to_date = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f\"Fetching articles from {from_date} to {to_date}\")\n",
    "\n",
    "queries = [\"Campaign financing AND 2024 election\", \"Voter turnout AND 2024\"]\n",
    "all_articles = []\n",
    "\n",
    "# Fetch articles for each query\n",
    "for query in queries:\n",
    "    all_articles.extend(fetch_articles(query, from_date, to_date))\n",
    "\n",
    "df = pd.DataFrame(all_articles)\n",
    "file_name = f\"general_{from_date}_to_{to_date}.csv\"\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"Saved {len(all_articles)} articles for General Election News.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine datasets - not sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "all_files = glob.glob(\"*.csv\")\n",
    "combined_df = pd.concat([pd.read_csv(file) for file in all_files])\n",
    "combined_df.drop_duplicates(subset=\"title\", inplace=True)\n",
    "combined_df.to_csv(\"final_combined_data.csv\", index=False)\n",
    "\n",
    "print(f\"Saved combined dataset with {len(combined_df)} unique articles.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02805SG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
